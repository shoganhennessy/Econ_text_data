---
title: ""
author: "Senan Hogan-Hennessy, "
date: "`r format(Sys.time(), '%d %b %Y')`"
output: github_document
---
This is the second of a series of blog posts motivating my analysis and exploration
of a huge set of data on economics publications, sho I hope you enjoy the posts.
The source code is available in [this repo](https://github.com/shoganhennessy/Econ_text_data/),
so feel free to look over and reproduce from there (which is filled mostly with code in *R* and *Python*).
Please contact me if you would like to use my underlying data for another project --
all of the used data are publicly accessible across the internet yet
my collection of them all may constitute sensitive data.

***

```{r setup, include=F}
knitr::opts_chunk$set(echo = F, message = F, warning = F, cache = T, fig.align = 'center')
library(tidyverse)
library(data.table)
library(plm)
#### Datafiles
# Load the data on Economists
Economists.data <- fread('../Data/RePEc_data/Economists_data/Economists_repec_data.csv')
# Load the data on published articles
Articles.data <- fread('../Data/RePEc_data/Papers_data/Journal_articles_repec.csv')
# Load Economist-article individual links -- made externally in Python
Economists_articles.links <- fread('../Data/RePEc_data/Economists_data/Economists_articles_repec.csv')
# Load info on journal rankings
Journals.data <- fread('../Data/RePEc_data/Journals_data/Journal_info_repec.csv')
```
# The Ideas.RePEc Listings of Articles in Economics
The NBER series is a great source of research in our profession, but it isn't the full picture of research in the field.
It is, after all, a listing of working papers which are not yet publications -- though most do go on to be published,
as I noted in the [last post.](https://github.com/shoganhennessy/Econ_text_data/blob/master/Blog_post_exploration/1_NBER_working_papers.md)

Fortunately, [Research Papers in Economics (RePEc)'s Ideas](https://ideas.repec.org/) provides a large listing of economics research which I can use as a complement to the NBER listings as it lists information on `r nrow(Economists.data) %>% format(big.mark=',', trim=T)` economists and `r nrow(Articles.data) %>% format(big.mark=',', trim=T)` published articles papers -- considering only those in English as of 9 January 2020.

> ''IDEAS is the largest bibliographic database dedicated to Economics and available freely on the Internet. 
> Based on RePEc, it indexes over 3,000,000 items of research, including over 2,700,000 that can be downloaded in full text.''
> 
> -- What is IDEAS?  [Ideas.RePEc.org/](https://ideas.repec.org/) 

`r nrow(Articles.data) %>% format(big.mark=',', trim=T)` is a huge number of articles to consider, and comparable in size to articles that use the near complete set of publications.<sup id="a1">[1](#f1)</sup>
RePEc has certain advantages: it is more open and it has a clear link to authors -- and importantly some of their characteristics -- to working and published papers, all within the field of economics.
It is however, a repository only within the economics sphere: citations are only counted among other papers in the database, and not among the universe of publications.

This post looks at two key measures of publication quality in economics:
citations and the top 5 journals.
The distribution of citations is looked at by visualisations with
discussion of how to interpret the statistics,
before the top 5 economics journals are investigated for their 
influential place in the field of economics as well as their place in these data.


### Citations

For a sanity check, take a look at the most prolific authors in the field by citation count.<sup id="a2">[2](#f2)</sup>
```{r, echo=F, results='asis'}
# The most prolific authors, within these data
## WHo have the most citations, in these data
Economists_citations.data <- Economists_articles.links %>% 
  left_join(select(Economists.data, url, name, 
                   institution, affiliation, degree,) %>% 
              rename(author_name = name, author_url = url), by = 'author_url') %>%
  left_join(rename(Articles.data, article_url = url), by = 'article_url') %>%
  select(author_name, institution, affiliation, degree, 
         title, publication_date, journal_title, citation_count) %>%
  filter(!is.na(citation_count)) %>%
  group_by(author_name) %>%
  summarise(total_citations = sum(citation_count, na.rm = T),
            mean_citations = round(mean(citation_count, na.rm = T)),
            total_articles = n()) %>%
  arrange(-total_citations)

# SHow the top ten 
Economists_citations.data %>% head(10) %>%
  knitr::kable(format = 'markdown')
```
There are some familiar faces among the names, which is to be expected! The process of assigning is, however, not perfect:
citations are assigned from each article to each author equally when there are multiple authors.
Yet [Sarsons (2017)](https://www.aeaweb.org/articles?id=10.1257/aer.p20171126) shows how inappropriate this accounting is
by exhibiting the unequal citation rate of return in among economists by gender --
which actually inspired me to work with economics publishing data in the first place!
Call it a point of interest to rank economists by better measures in the future, as this project progresses.

The above top ten are at the very top of the field and
citations are, of course, not evenly distributed across researchers in the field.
So what does the wider distribution look like?
```{r, echo=F, fig.height = 4, fig.width = 7}
# Measure skew
citations.skew <- Economists_citations.data %>%
	pull(total_citations) %>%
	moments::skewness() %>%
	round(2) %>% as.character()

# Histogram of authors' citations
Economists_citations.data %>%
  ggplot(aes(x = total_citations)) + theme_bw() +
  geom_histogram(aes(y = ..count..), bins=50, colour='black', fill='#FF6666', alpha=0.2) +
  scale_x_log10(name = 'Total Citations (log scale)',
   breaks = scales::trans_breaks('log10', function(x) 10^x),
   labels = scales::trans_format('log10', scales::math_format(10^.x))) +
  scale_y_continuous(name = 'Author count') + 
  labs(caption = paste0('Skew: ', citations.skew))
```

Citations are positively skewed among authors, so much so that
the distribution above can only be visualised well with a log scale in citations:
the top of the distribution has orders of magnitude more citations than the rest.
One might call this distribution *unequal*, but is the distribution *unequal* for all the years of these data?
```{r, echo=F, fig.height = 3.5, fig.width = 7}
# Dataframe of author citations by year
Author_citations.data <- Economists_articles.links %>%
  left_join(select(Economists.data, url, name,
            institution, affiliation, degree) %>%
            rename(author_name = name, author_url = url), 
			by = 'author_url') %>%
  left_join(rename(Articles.data, article_url = url), by = 'article_url') %>%
  group_by(author_name, publication_date) %>%
  summarise(citation_count = sum(citation_count)) 

# Gini coefficient for authors' citations, by year
Author_citations.data %>%
  filter(!is.na(citation_count)) %>%
  group_by(publication_date) %>%
  summarise(gini_coefficient = reldist::gini(citation_count)) %>%
  filter(publication_date > 1975) %>%
  ggplot(aes(x = publication_date, y = gini_coefficient)) +
  geom_line(colour = 'orange') + theme_bw() +
  scale_x_continuous(name = 'Among papers published in year',
    breaks = seq(1975, 2020, by = 5)) +
  scale_y_continuous(name = 'Citations Gini Index (among authors)',
                     breaks = seq(0.2, 0.6, by = 0.1), limits = c(0.2,0.6))
```

The Gini coefficient measures income inequality in economics, where
0 is perfect equality and 1 perfect inequality.
The coefficient is stable among citations for authors per year between 0.5 and 0.45,
which (perhaps) implies a distribution with only moderate inequality -- 
compare it to the US income distribution, which has a similar value.
Yet it is not fully clear what this entails;
citation counts are not income so that the comparison does not hold direct meaning.
A Gini coefficient, while interesting, is a crude measure of inequality among publications.
```{r, echo = F, fig.height = 5, fig.width = 10}
# create a citation count per economist per year and year since first publication
Author_citation_count.data <- Economists_articles.links %>% 
  left_join(select(Economists.data, url, name, 
                   institution, affiliation, degree,) %>% 
              rename(author_name = name, author_url = url), by = 'author_url') %>%
  left_join(rename(Articles.data, article_url = url), by = 'article_url') %>%
  select(author_name, institution, affiliation, degree, 
         title, publication_date, journal_title, citation_count) %>%
  filter(!is.na(citation_count)) %>%
  group_by(author_name, publication_date) %>%
  summarise(total_citations = sum(citation_count),
            articles_count = n()) %>%
  arrange(author_name, publication_date) %>% 
  group_by(author_name) %>%
  mutate(since_first = publication_date - first(publication_date))

# Add empty values for years since up to 40 if not listed in data (i.e. didn't publish in that year)
distinct_names <- Author_citation_count.data %>% 
  select(author_name) %>% distinct() %>% pull(author_name)
balanced_data <- matrix(ncol = 2, nrow = 41*length(distinct_names)) %>% data.frame()
colnames(balanced_data) <- c('author_name', 'since_first')
balanced_data$author_name <- distinct_names %>%
  lapply(function(x) rep(x, 41)) %>%
  unlist()
balanced_data$since_first <- c(0:40) %>% rep(length(distinct_names))

## add on missing values and a cumulative count of citations
Author_cumulative_citations.data <- balanced_data %>% 
  left_join(Author_citation_count.data) %>%
  replace_na(list(total_citations = 0, articles_count = 0)) %>%
  group_by(author_name) %>%
  mutate(publication_date = c(1:n()) - 1 + first(publication_date)) %>%
  filter(publication_date < 2020)

## Create a dataframe of total, mean
Yearly_cumulative_citations.data <- Author_cumulative_citations.data %>%
  mutate(total_citations_empty = ifelse(articles_count > 0, total_citations, NA)) %>%
  group_by(since_first) %>%
  summarise(mean_citations_restricted = mean(total_citations_empty, na.rm = T),
            mean_citations_unrestricted = mean(total_citations)) %>%
  arrange(since_first) %>%
  mutate(cum_citations_restricted = cumsum(mean_citations_restricted),
         cum_citations_unrestricted = cumsum(mean_citations_unrestricted))

# two lines: one considering only years in which author publishes at least once,
#            one considering all years
# Mean citations every year since first publication
mean_citations_year.graph <- Yearly_cumulative_citations.data %>%
  ggplot(aes(x = since_first)) +
  geom_point(aes(y = mean_citations_restricted,
             colour = 'At least one\npublication\nin that year\n')) +
  geom_smooth(aes(y = mean_citations_restricted,
              colour = 'At least one\npublication\nin that year\n'), span = 0.25, se = F) +
  geom_point(aes(y = mean_citations_unrestricted, colour = 'All years')) +
  geom_smooth(aes(y = mean_citations_unrestricted, colour = 'All years'), span = 0.25, se = F) +
  scale_x_continuous(name = 'Year Since First Publication', breaks = seq(0, 40, by = 5)) +
  scale_y_continuous(name = 'Mean Citations', limits = c(0, 120)) +
  theme_bw()+ theme(legend.position = 'none') +
  scale_color_manual('Restriction',
    breaks = c('At least one\npublication\nin that year\n', 'All years'),
    values = c('At least one\npublication\nin that year\n' = 'darkviolet',
               'All years' = 'chartreuse4'))
# Cum citations every year since first publication
cum_citations_year.graph <- Yearly_cumulative_citations.data %>%
  ggplot(aes(x = since_first)) +
  geom_point(aes(y = cum_citations_restricted,
             colour = 'At least one\npublication\nin that year\n')) +
  geom_smooth(aes(y = cum_citations_restricted,
              colour = 'At least one\npublication\nin that year\n'), span = 0.25, se = F) +
  geom_point(aes(y = cum_citations_unrestricted, colour = 'All years')) +
  geom_smooth(aes(y = cum_citations_unrestricted, colour = 'All years'), span = 0.25, se = F) +
  scale_x_continuous(name = 'Year Since First Publication', breaks = seq(0, 40, by = 5)) +
  scale_y_continuous(name = 'Cumulative Citations') +
  theme_bw() + theme(legend.position = c(0.8, 0.5)) +
  scale_color_manual('Restriction',
    breaks = c('At least one\npublication\nin that year\n', 'All years'),
    values = c('At least one\npublication\nin that year\n' = 'darkviolet',
               'All years' = 'chartreuse4'))
# Plot both mean and cumulative
gridExtra::grid.arrange(mean_citations_year.graph, cum_citations_year.graph, nrow = 1)
```
The above shows means of yearly and cumulative citations across every author following their first publication.
Be aware that the measure considers citations of papers, so that citations
are attributed to the year of publication and not the year of citation being made.<sup id="a3">[3](#f1)</sup> 

My data set of papers is formatted at the individual paper level (each row is a paper),
so that summary statistics on this only consider years in which papers appear,
a measure of citations conditional on active publication in that year
(giving the purple lines).  Another measure includes years when authors do not
publish, where citations in that year are zero, an unrestricted measure of citations 
(giving the green lines).
If there is at least one publication in that year, citations in papers after the first are
relatively constant for the following years around 100 to 120.
Without this restriction mean citations fall from around 20 to 10, showing attenuation
in the group of authors who continue to publish years after their first paper. 


### The Top 5

It well known in economics that the top five journals holds an outside influence in
publishing and the power structure of our field.
Recently this has been referred to as a tyranny 
([Heckman, Moktan 2020 forthcoming](
https://www.aeaweb.org/articles?id=10.1257/jel.20191574&&from=f)), 
where publishing in one of these journals heavily influences a tenure decision and thus 
makes (or breaks) an academic economics career.

```{r, echo=F, fig.height = 4, fig.width = 7}
# top 5 journals
Top5_journals <- c('American Economic Review',
                   'Journal of Political Economy',
                   'The Quarterly Journal of Economics',
                   'Econometrica',
                   'Review of Economic Studies')

# graph count of top 5, per year
Articles.data %>% 
  filter(!is.na(publication_date)) %>%
  group_by(journal_title, publication_date) %>%
  summarise(total_articles = n()) %>%
  filter(journal_title %in% Top5_journals, total_articles > 0) %>%
  ggplot() + geom_line(aes(x = publication_date, y = total_articles, colour = journal_title)) +
  scale_x_continuous(name = 'Year', breaks = seq(1935, 2020, by = 10), limits = c(1935, 2020)) +
  scale_y_continuous(name = 'Count of Publications') +
  theme_bw() + theme(legend.position = c(0.25, 0.75))
# How many total in data?
Top5.count <- Articles.data %>% 
  filter(!is.na(publication_date))  %>%
  filter(journal_title %in% Top5_journals) %>% nrow()
```

The top 5 journals are comprised of the American Economic Review, Econometrica, the Journal of Political Economy,
the Quarterly Journal of Economics, and the Review of Economic Studies.
These data contain `r Top5.count %>% format(big.mark=',', trim=T)` total articles from the top 5,
showing a clear rise in the number released by AER to the end of the 20th century -- but also sample attrition from the year 2018 and on.

We see the top 10 ranked by mean citations, which naturally has the top 5 at the top (who would have thought?).
Notably the top 5 are not the first five when ranked by citations per article though they do rank at rank very highly in that regard.
This is documented previously by [Anauati et al. (2018)](https://onlinelibrary.wiley.com/doi/abs/10.1111/ecin.12867).

```{r, echo = F, results='asis'}
Journals_articles.data <- Articles.data %>% 
  filter(!is.na(citation_count) & !is.na(publication_date)) %>%
  group_by(journal_title) %>%
  summarise(mean_citations = round(mean(citation_count, na.rm = T)),
            total_citations = sum(citation_count, na.rm = T),
            total_articles = n()) %>%
  arrange(-total_citations)

Journals_articles.data %>% head(10) %>% 
  knitr::kable(format = 'markdown',
    col.names = c('Journal name', 'Mean citations per article', 'Total citations', 'Count articles'))
```

Economics' focus on the top 5 has been been dubbed *Top5itis*, a disease inflicting our field
leading to tunnel vision for those with power in our field.
While humorous in description,
the problem is nonetheless real, and these data give a perfect opportunity to observe 
and study the phenomenon.  The design below is a start in using these data for this purpose,
hopefully leading to work on how to address the problem.

> Indeed, serious theoretical and empirical
> work should be conducted to understand this disease better and suggest possible treatments. The problem
> will probably require challenging techniques in applied mechanism design.
> 
> -- [Top5itis, R Serrano (2018)](http://hdl.handle.net/10419/202594)


### Top 5 Publication as an event

If publication in a top journal really can change a career, then it makes sense to think about as an *event*.
This can be drawn as a linear model, with a coefficient on the year of the author's first publication in the top5
(including fixed effects for author *i* and calendar year *t*), to give an event study for publication in a top journal.
The outcome of interest here can be a measure of academic success, which here will be
log citations for author *i* in year *t*.
<p align="center">
  <img src="2_RePEc_listings_files/CodeCogsEqn.svg" />
</p>

The design can similarly be applied to the next 5 prestigious journals (of the top 10 ranking),
to give a similar event to compare.

```{r, echo = F, fig.height = 5, fig.width = 10}
# Define the omparable next 5 journals
TopOther_journals <- Journals_articles.data %>% head(10) %>% 
  pull(journal_title) %>% setdiff(Top5_journals)

# Find date of a top 5 and Top other journal for each author
Author_cumulative_citations.data <- Economists_articles.links %>% 
  left_join(select(Economists.data, url, name, 
                   institution, affiliation, degree,) %>% 
              rename(author_name = name, author_url = url), by = 'author_url') %>%
  left_join(rename(Articles.data, article_url = url), by = 'article_url') %>%
  select(author_name, institution, affiliation, degree, 
         title, publication_date, journal_title, citation_count) %>%
  mutate(top5 = as.numeric(journal_title %in% Top5_journals),
         topother = as.numeric(journal_title %in% TopOther_journals)) %>%
  group_by(author_name, publication_date) %>%
  summarise(top5_count = sum(top5),
            topother_count = sum(topother)) %>%
  filter(top5_count + topother_count > 0) %>%
  right_join(Author_cumulative_citations.data) %>%
  replace_na(list(top5_count = 0, topother_count = 0))
  
# Top5_since
Top5_since.data <- Author_cumulative_citations.data %>%
  mutate(top5 = as.numeric(top5_count > 0)) %>%
  arrange(author_name, publication_date) %>%
  group_by(author_name) %>% filter(max(top5) > 0) %>%
  mutate(since_first_top5 = publication_date - min(((top5!=1)+1) * publication_date)) %>%
  select(author_name, publication_date, top5,
         since_first_top5, total_citations) %>%
  arrange(author_name, since_first_top5) %>% ungroup()

# Top other since
Topother_since.data <- Author_cumulative_citations.data %>%
  mutate(topother = as.numeric(topother_count > 0)) %>%
  group_by(author_name) %>% filter(max(topother) > 0) %>%
  mutate(since_first_topother = publication_date - min(((topother!=1)+1) * publication_date)) %>%
  select(author_name, publication_date, topother,
         since_first_topother, total_citations) %>%
  arrange(author_name, since_first_topother) %>% ungroup()


##############################
## Draw event study style graphs
#### 1.
# Event for a top 5 publication
Top5.eventstudy <- Top5_since.data %>%
  filter(abs(since_first_top5) < 16 & total_citations > 0) %>%
  pdata.frame(index = c('author_name', 'publication_date')) %>%
  plm(log(total_citations) ~ 0 + as.factor(since_first_top5), data = .,
      effect = 'twoways', model = 'random')
anotation_note <- Top5.eventstudy %>% summary() %>% capture.output() %>% nth(8)
# And cluster the SE, keeping relevant coefficients
Top5.eventstudy <- Top5.eventstudy %>%
  lmtest::coeftest(vcov=vcovDC(Top5.eventstudy, type = 'sss')) %>%
  broom::tidy() %>% filter(str_detect(term, 'since_first_top5')) %>%
  mutate(coefficient = as.numeric(str_extract(term, '[^)]+$'))) %>%
  mutate(conf.low = estimate - 1.96*std.error,
         conf.high= estimate + 1.96*std.error)
# Graph the event
Top5_event.graph <- Top5.eventstudy %>%
  mutate(estimate_before  = ifelse(coefficient < 0 , estimate, NA),
         estimate_after   = ifelse(0 <= coefficient, estimate, NA),
         conf.low_before  = ifelse(coefficient < 0,  conf.low, NA),
         conf.low_after   = ifelse(0 < coefficient, conf.low, NA),
         conf.high_before = ifelse(coefficient < 0,  conf.high, NA),
         conf.high_after  = ifelse(0 < coefficient, conf.high, NA)) %>%
  ggplot(aes(x = coefficient)) +
  geom_point(aes(y = estimate)) +
  stat_smooth(aes(y = estimate), geom='line', colour='blue', span=0.5, alpha=0.5, se=F) +
  geom_line(aes(y = conf.low_before), linetype = 'dashed') +
  geom_line(aes(y = conf.low_after), linetype = 'dashed') +
  geom_line(aes(y = conf.high_before), linetype = 'dashed') +
  geom_line(aes(y = conf.high_after), linetype = 'dashed') +
  geom_smooth(aes(y = estimate_before), method = 'lm', se = F, colour = 'red') +
  geom_smooth(aes(y = estimate_after), method = 'lm', se = F, colour = 'red') +
  scale_x_continuous(name = 'Years after publication', breaks = seq(-20, 20, by = 5)) +
  scale_y_continuous(name = 'Coefficient estimate', limits = c(3.75,4.5), breaks = seq(3.75,4.5,by=0.125)) + 
  theme_bw() + theme(plot.title = element_text(hjust = 0.5)) +
  labs(title   = 'Log Citations by year to author first\ntop 5 publication',
       caption = anotation_note)

#### 2.
# Draw event study style graph, for the top other
Topother.eventstudy <- Topother_since.data %>%
  filter(abs(since_first_topother) < 16 & total_citations > 0) %>%
  pdata.frame(index = c('author_name', 'publication_date')) %>%
  plm(log(total_citations) ~ 0 + as.factor(since_first_topother), data = .,
      effect = 'twoways', model = 'random')
anotation_note <- Topother.eventstudy %>% summary() %>% capture.output() %>% nth(8)
# And cluster the SE, keeping relevant coefficients
Topother.eventstudy <- Topother.eventstudy %>%
  lmtest::coeftest(vcov=vcovDC(Topother.eventstudy, type = 'sss')) %>%
  broom::tidy() %>% filter(str_detect(term, 'since_first_topother')) %>%
  mutate(coefficient = as.numeric(str_extract(term, '[^)]+$'))) %>%
  mutate(conf.low = estimate - 1.96*std.error,
         conf.high= estimate + 1.96*std.error)
# Graph the event
Topother_event.graph <- Topother.eventstudy %>%
  mutate(estimate_before  = ifelse(coefficient < 0 , estimate, NA),
         estimate_after   = ifelse(0 <= coefficient, estimate, NA),
         conf.low_before  = ifelse(coefficient < 0,  conf.low, NA),
         conf.low_after   = ifelse(0 < coefficient, conf.low, NA),
         conf.high_before = ifelse(coefficient < 0,  conf.high, NA),
         conf.high_after  = ifelse(0 < coefficient, conf.high, NA)) %>%
  ggplot(aes(x = coefficient)) +
  geom_point(aes(y = estimate)) +
  stat_smooth(aes(y = estimate), geom='line', colour='blue', span=0.5, alpha=0.5, se=F) +
  geom_line(aes(y = conf.low_before), linetype = 'dashed') +
  geom_line(aes(y = conf.low_after), linetype = 'dashed') +
  geom_line(aes(y = conf.high_before), linetype = 'dashed') +
  geom_line(aes(y = conf.high_after), linetype = 'dashed') +
  geom_smooth(aes(y = estimate_before), method = 'lm', se = F, colour = 'red') +
  geom_smooth(aes(y = estimate_after), method = 'lm', se = F, colour = 'red') +
  scale_x_continuous(name = 'Years after publication', breaks = seq(-20, 20, by = 5)) +
  scale_y_continuous(name = '', limits = c(3.75,4.5), breaks = seq(3.75,4.5,by=0.125)) + 
  theme_bw() + theme(plot.title = element_text(hjust = 0.5)) +
  labs(title   = 'Log Citations by year to author first\ntop other publication',
       caption = anotation_note)

######################
## Plot both events
gridExtra::grid.arrange(Top5_event.graph, Topother_event.graph, nrow = 1)
```

In terms of log citations, authors have a real and persistant bump 
to their citations in years following their first publication in a top 5 journal.
The bump also exists for the first publication in one of the next most respected
journals (the comparison figure on the right),
and is at least smaller than that for the top 5.

Be aware that this is a relatively simple linear model:
it shows not much more than the fact authors once published in the top 5 receive more citations
over the next 15 years.  There's no causal identification (or inference), 
the measure of citations is still from
year published,<sup id="a4">[3](#f3)</sup> and sample selction is likely rampant in this design.
For example, the model considers both authors who get to the top 5 in their second active year of writing
with people who finally make it after 16 active years, despite these authors are not likely comparable
(even with fixed effects included).

Lastly, the citation count measure used throughout these sections 
is an easy measure of research success for this and other projects
thanks to its availability, yet
is an imperfect measure of actual research penetration.
In fact its use as a goal for researchers, and following
*citation maximisation* behaviour is speculated to be part of
the stagnation in science research advances
([Bhattacharya, Packalen 2020](https://www.nber.org/papers/w26752)).
So it pays to take analyses of citations, such as the ones in this post, with a grain of salt.


### Conclusion: 

This post described the IDEAS.RePEc data, and the opportunity it represents to
to measure economics publication and their outcomes.
Hopefully use of these data and further ''applied mechanism design''
([Serrano 2018](http://hdl.handle.net/10419/202594)) will help us
understand the world of economics publications better.


**Next up:** Looking at inclusion in the *NBER family*.

***
### Footnotes
<b id="f1">1</b> [Angrist et al. (2017)](https://www.nber.org/papers/w23698) link Econlit and Web of Science for similar coverage, for example.[↩](#a1)

<b id="f2">2</b> Again, note that this citation count is not the same as that in the universe of academic publications or Google Scholar, it is a count of the citations within the RePEc listings so a measure of citations within only this large coverage of the field.[↩](#a2)

<b id="f3">3</b> The count of citations when they are made is *significantly* more difficult to create, yet is in the works.[↩](#a3)

***
### References
Anauati, M. V., Galiani, S., & Gálvez, R. H. (2018). Differences in citation patterns across journal tiers: The case of economics. Economic Inquiry.

Angrist, J., Azoulay, P., Ellison, G., Hill, R., & Lu, S. F. (2017). Inside job or deep impact? Using extramural citations to assess economic scholarship (No. w23698). National Bureau of Economic Research.

Bhattacharya, J., & Packalen, M. (2020). Stagnation and Scientific Incentives (No. w26752). National Bureau of Economic Research.

Heckman J, & S Moktan. (2020) Publishing and Promotion in Economics: The Tyranny of the Top Five.  Journal of Economic Literatue (forthcoming).

Sarsons, H. (2017). Recognition for group work: Gender differences in academia. American Economic Review, 107(5), 141-45.

Serrano, R. (2018). Top5itis (No. 2018-2). Working Paper.
